{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fbd582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8380fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9840b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| NAME| AGE|EXPERIENCE|SALARY|\n",
      "+-----+----+----------+------+\n",
      "| JON |  31|        10| 30000|\n",
      "|  VON|  53|        20| 60000|\n",
      "|  RON|  25|         2| 10000|\n",
      "|BJORK|  23|         1| 10000|\n",
      "| DORK|null|      null| 30000|\n",
      "| null|  34|        10| 20000|\n",
      "| null|  36|      null|  null|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c122d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| NAME|AGE|EXPERIENCE|SALARY|\n",
      "+-----+---+----------+------+\n",
      "| JON | 31|        10| 30000|\n",
      "|  VON| 53|        20| 60000|\n",
      "|  RON| 25|         2| 10000|\n",
      "|BJORK| 23|         1| 10000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a175795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| NAME|AGE|EXPERIENCE|SALARY|\n",
      "+-----+---+----------+------+\n",
      "| JON | 31|        10| 30000|\n",
      "|  VON| 53|        20| 60000|\n",
      "|  RON| 25|         2| 10000|\n",
      "|BJORK| 23|         1| 10000|\n",
      "+-----+---+----------+------+\n",
      "\n",
      "+-----+----+----------+------+\n",
      "| NAME| AGE|EXPERIENCE|SALARY|\n",
      "+-----+----+----------+------+\n",
      "| JON |  31|        10| 30000|\n",
      "|  VON|  53|        20| 60000|\n",
      "|  RON|  25|         2| 10000|\n",
      "|BJORK|  23|         1| 10000|\n",
      "| DORK|null|      null| 30000|\n",
      "| null|  34|        10| 20000|\n",
      "| null|  36|      null|  null|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## drop takes some arguments, if how==all this would return a DF without rows with complete null vals.\n",
    "df_pyspark.na.drop(how='any').show()\n",
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23e17f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| NAME| AGE|EXPERIENCE|SALARY|\n",
      "+-----+----+----------+------+\n",
      "| JON |  31|        10| 30000|\n",
      "|  VON|  53|        20| 60000|\n",
      "|  RON|  25|         2| 10000|\n",
      "|BJORK|  23|         1| 10000|\n",
      "| DORK|null|      null| 30000|\n",
      "| null|  34|        10| 20000|\n",
      "| null|  36|      null|  null|\n",
      "+-----+----+----------+------+\n",
      "\n",
      "+-----+---+----------+------+\n",
      "| NAME|AGE|EXPERIENCE|SALARY|\n",
      "+-----+---+----------+------+\n",
      "| JON | 31|        10| 30000|\n",
      "|  VON| 53|        20| 60000|\n",
      "|  RON| 25|         2| 10000|\n",
      "|BJORK| 23|         1| 10000|\n",
      "| null| 34|        10| 20000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## threshold is another parameter of drop;\n",
    "## it checks the number of non null values in a row,if this condition is not met,\n",
    "## then the row is removed.\n",
    "\n",
    "df_pyspark.show()\n",
    "df_pyspark.na.drop(thresh = 3).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59eec7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| NAME| AGE|EXPERIENCE|SALARY|\n",
      "+-----+----+----------+------+\n",
      "| JON |  31|        10| 30000|\n",
      "|  VON|  53|        20| 60000|\n",
      "|  RON|  25|         2| 10000|\n",
      "|BJORK|  23|         1| 10000|\n",
      "| DORK|null|      null| 30000|\n",
      "| null|  34|        10| 20000|\n",
      "| null|  36|      null|  null|\n",
      "+-----+----+----------+------+\n",
      "\n",
      "+-----+---+----------+------+\n",
      "| NAME|AGE|EXPERIENCE|SALARY|\n",
      "+-----+---+----------+------+\n",
      "| JON | 31|        10| 30000|\n",
      "|  VON| 53|        20| 60000|\n",
      "|  RON| 25|         2| 10000|\n",
      "|BJORK| 23|         1| 10000|\n",
      "| null| 34|        10| 20000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## subset;\n",
    "## Removes the rows containing null values in a specific row.\n",
    "df_pyspark.show()\n",
    "df_pyspark.na.drop(subset=['EXPERIENCE']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e8e266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| NAME|AGE|EXPERIENCE|SALARY|\n",
      "+-----+---+----------+------+\n",
      "| JON | 31|        10| 30000|\n",
      "|  VON| 53|        20| 60000|\n",
      "|  RON| 25|         2| 10000|\n",
      "|BJORK| 23|         1| 10000|\n",
      "| DORK|  0|         0| 30000|\n",
      "| null| 34|        10| 20000|\n",
      "| null| 36|         0|     0|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Filling the missing values\n",
    "\n",
    "df_pyspark.na.fill(value=0,subset=['AGE','EXPERIENCE','SALARY']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c95f65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| NAME| AGE|EXPERIENCE|SALARY|\n",
      "+-----+----+----------+------+\n",
      "| JON |  31|        10| 30000|\n",
      "|  VON|  53|        20| 60000|\n",
      "|  RON|  25|         2| 10000|\n",
      "|BJORK|  23|         1| 10000|\n",
      "| DORK|null|      null| 30000|\n",
      "| null|  34|        10| 20000|\n",
      "| null|  36|      null|  null|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Filling missing values with mean of that column using imputer function\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04b46ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['AGE','EXPERIENCE','SALARY'],\n",
    "    outputCols=[f\"{c}_imputed\" for c in ['AGE','EXPERIENCE','SALARY']]\n",
    ").setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51f16f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "| NAME| AGE|EXPERIENCE|SALARY|AGE_imputed|EXPERIENCE_imputed|SALARY_imputed|\n",
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "| JON |  31|        10| 30000|         31|                10|         30000|\n",
      "|  VON|  53|        20| 60000|         53|                20|         60000|\n",
      "|  RON|  25|         2| 10000|         25|                 2|         10000|\n",
      "|BJORK|  23|         1| 10000|         23|                 1|         10000|\n",
      "| DORK|null|      null| 30000|         31|                10|         30000|\n",
      "| null|  34|        10| 20000|         34|                10|         20000|\n",
      "| null|  36|      null|  null|         36|                10|         20000|\n",
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63d343f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| NAME|AGE|EXPERIENCE|SALARY|\n",
      "+-----+---+----------+------+\n",
      "| JON | 31|        10| 30000|\n",
      "|  VON| 53|        20| 60000|\n",
      "|  RON| 25|         2| 10000|\n",
      "|BJORK| 23|         1| 10000|\n",
      "| DORK| 33|         8| 30000|\n",
      "| null| 34|        10| 20000|\n",
      "| null| 36|         8| 26666|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer = Imputer(\n",
    "    inputCols=['AGE','EXPERIENCE','SALARY'],\n",
    "    outputCols=['AGE','EXPERIENCE','SALARY']\n",
    ").setStrategy(\"mean\")\n",
    "\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10071dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
